{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "detect_and_classify.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Mm2mzu0HckY6",
        "axCgvGhYGupX",
        "l92ApLtb1NpS",
        "9a0gM7hDEOTB",
        "dnf0Pfd0Zr1U",
        "fOK9iNHNaBkQ",
        "Ctcf0hMOaFJY",
        "C67lAKamaSMg",
        "jBZhYAldaas9",
        "C13CpWu90_v2"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vernalhav/image_processing_project/blob/main/detect_and_classify.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mm2mzu0HckY6"
      },
      "source": [
        "# Our Solution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7tf9jhC8028H"
      },
      "source": [
        "## Useful Methods"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NfS1L3rThtAh",
        "outputId": "3e6d518f-983a-43c2-8f6f-8e8453ef566a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /drive; to attempt to forcibly remount, call drive.mount(\"/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3vxSZ-3fP8H"
      },
      "source": [
        "DEBUG = False\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "import imutils"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-uPcIXdkfP8K"
      },
      "source": [
        "def show_cvt(image, n):\n",
        "    plt.figure(figsize=(n,n))\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    \n",
        "    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "def show(image, n):\n",
        "    plt.figure(figsize=(n,n))\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(image,15)  \n",
        "\n",
        "def imshow_components(labels):\n",
        "    # Map component labels to hue val\n",
        "    label_hue = np.uint8(179*labels/np.max(labels))\n",
        "    blank_ch = 255*np.ones_like(label_hue)\n",
        "    labeled_img = cv2.merge([label_hue, blank_ch, blank_ch])\n",
        "\n",
        "    # cvt to BGR for display\n",
        "    labeled_img = cv2.cvtColor(labeled_img, cv2.COLOR_HSV2BGR)\n",
        "\n",
        "    # set bg label to black\n",
        "    labeled_img[label_hue==0] = 0\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    plt.imshow(labeled_img)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "def draw_box(img, north, west, height, width):\n",
        "    east = west\n",
        "    south = north\n",
        "    east[1] += width\n",
        "    south[1] += height\n",
        "\n",
        "    cv2.line(img, (west[1], south[0]), (east[1], south[0]), (255, 0, 0), 5, 1)\n",
        "    cv2.line(img, (west[1], north[0]), (east[1], north[0]), (255, 0, 0), 5, 1)\n",
        "    cv2.line(img, (west[1], south[0]), (west[1], north[0]), (255, 0, 0), 5, 1)\n",
        "    cv2.line(img, (east[1], north[0]), (east[1], south[0]), (255, 0, 0), 5, 1)\n",
        "\n",
        "    return img\n",
        "\n",
        "def extract_color_histogram(image, bins=(2, 2, 2)):\n",
        "\t# extract a 3D color histogram from the HSV color space using\n",
        "\t# the supplied number of `bins` per channel\n",
        "\thsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
        "\thist = cv2.calcHist([hsv], [0, 1, 2], None, bins,\n",
        "\t\t[0, 180, 0, 256, 0, 256])\n",
        "\t\n",
        "    # handle normalizing the histogram if we are using OpenCV 2.4.X\n",
        "\tif imutils.is_cv2():\n",
        "\t\thist = cv2.normalize(hist)\n",
        "\t# otherwise, perform \"in place\" normalization in OpenCV 3 (I\n",
        "\t# personally hate the way this is done\n",
        "\telse:\n",
        "\t\tcv2.normalize(hist, hist)\n",
        "\t\n",
        "    # return the flattened histogram as the feature vector\n",
        "\treturn hist.flatten()\n",
        "\n",
        "def extract_sift(image):\n",
        "    sift = cv2.xfeatures2d.SIFT_create()\n",
        "    kp, des = sift.detectAndCompute(gray,None)\n",
        "    return des\n",
        "\n",
        "def extract_sobel(image):\n",
        "    NUM_FILTERS = 16\n",
        "    gabor = []\n",
        "    \n",
        "    for i in range(NUM_FILTERS):\n",
        "        gabor.append(cv2.getGaborKernel((5, 5), 8.0, (np.pi/NUM_FILTERS) * (i), 5.0, 0.5, 0, ktype=cv2.CV_32F))\n",
        "\n",
        "    filtered = []\n",
        "    # fig = plt.figure(figsize=(30,30))\n",
        "    for i in range(NUM_FILTERS):\n",
        "        filtered_img = cv2.filter2D(image,3,gabor[i])\n",
        "        filtered_img = ((filtered_img/np.max(filtered_img))*255).astype(np.uint8)\n",
        "        filtered_img = cv2.cvtColor(filtered_img, cv2.COLOR_BGR2GRAY)\n",
        "        filtered_img = cv2.bitwise_not(filtered_img)\n",
        "        # ax = fig.add_subplot(1,NUM_FILTERS,i + 1)\n",
        "        # ax.imshow(filtered_img, cmap=\"gray\")\n",
        "        #resizing features\n",
        "        filtered.append(cv2.resize(filtered_img, (10,10)))\n",
        "    return np.array(filtered)\n",
        "\n",
        "\n",
        "def characterize(img):\n",
        "    img = cv2.resize(img,(30,30))\n",
        "    \n",
        "    #extract color and shape features\n",
        "    colors = extract_color_histogram(img)\n",
        "    \n",
        "    return colors"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axCgvGhYGupX"
      },
      "source": [
        "## Pre-processing Image methods\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l92ApLtb1NpS"
      },
      "source": [
        "### Changing Color space"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBCUALf4G3-C"
      },
      "source": [
        "def change_color_space(img):\n",
        "    img_lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
        "\n",
        "    if DEBUG:\n",
        "        fig = plt.figure(figsize=(100,100))\n",
        "        ax1 = fig.add_subplot(1,3,1)\n",
        "        ax2 = fig.add_subplot(1,3,2)\n",
        "        ax3 = fig.add_subplot(1,3,3)\n",
        "\n",
        "        ax1.set_xticks([])\n",
        "        ax1.set_yticks([])\n",
        "        ax1.grid(False)\n",
        "        ax2.set_xticks([])\n",
        "        ax2.set_yticks([])\n",
        "        ax2.grid(False)\n",
        "        ax3.set_xticks([])\n",
        "        ax3.set_yticks([])\n",
        "        ax3.grid(False)\n",
        "\n",
        "        ax1.imshow(img_lab[:,:,0], cmap=\"gray\")\n",
        "        ax2.imshow(img_lab[:,:,1] , cmap=\"gray\")\n",
        "        ax3.imshow(img_lab[:,:,0] + img_lab[:,:,1], cmap=\"gray\")\n",
        "\n",
        "        plt.figure(figsize=(15,15))\n",
        "        plt.xticks([])\n",
        "        plt.yticks([])\n",
        "        plt.grid(False)\n",
        "\n",
        "        plt.imshow(img_lab[:,:,0] + img_lab[:,:,1], cmap=\"gray\")\n",
        "\n",
        "    return img_lab"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9a0gM7hDEOTB"
      },
      "source": [
        "### Selecting only important channels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvL9ofLWELS0"
      },
      "source": [
        "def select_important_channels(img_lab):\n",
        "    channels = img_lab[:,:,0] + img_lab[:,:,1]\n",
        "\n",
        "    return channels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dnf0Pfd0Zr1U"
      },
      "source": [
        "## Detection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LoL0RPW1aWvU"
      },
      "source": [
        "### Cell detection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9aeIEpWx7uN"
      },
      "source": [
        "def detect_cells(img):\n",
        "    \n",
        "    #searching for circles around cells\n",
        "    circles = cv2.HoughCircles(img, \n",
        "                    cv2.HOUGH_GRADIENT, 1, 20, param1 = 50,\n",
        "                param2 = 40, minRadius = 10, maxRadius = 55)\n",
        "\n",
        "    #removing overlaid circles\n",
        "    circles_ord = list(circles.copy()[0])\n",
        "\n",
        "    circles_ord.sort(key=lambda tup: tup[2], reverse=True)\n",
        "\n",
        "    circles_ord = np.array(circles_ord)\n",
        "\n",
        "    cells = []\n",
        "\n",
        "    collided = False\n",
        "    for circle1 in circles_ord:\n",
        "        for circle2 in cells:\n",
        "            dist = np.sqrt( ( circle1[0] - circle2[0])**2 + (circle1[1] - circle2[1])**2 )\n",
        "\n",
        "            #are they overlapping a lot?\n",
        "            if dist < circle1[2] + circle2[2] and dist < max(circle1[2], circle2[2]):\n",
        "                collided = True\n",
        "                break\n",
        "        if not collided:\n",
        "            cells.append(circle1)\n",
        "        else:\n",
        "            collided = False\n",
        "    \n",
        "    return cells"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fte2MwyLLQsl"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Qn0PA0e4QIS"
      },
      "source": [
        "## Classifier methods"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fOK9iNHNaBkQ"
      },
      "source": [
        "### Load model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KDm59UoF49Qh"
      },
      "source": [
        "def load_model(path):\n",
        "    #loading the model\n",
        "    import pickle\n",
        "\n",
        "    f = open(path, 'rb')\n",
        "    model = pickle.load(f)\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ctcf0hMOaFJY"
      },
      "source": [
        "### Classify cells"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCaeldLMpYj4"
      },
      "source": [
        "def classify_cells(img, cells, model):\n",
        "    \n",
        "    cimg = img.copy()\n",
        "\n",
        "    margin = 20\n",
        "\n",
        "    dead_count = 0\n",
        "    alive_count = 0\n",
        "\n",
        "    #classifying the im-age crops\n",
        "\n",
        "    for i in cells:\n",
        "        # draw the outer circle\n",
        "        \n",
        "        top = int(i[0] - i[2] - margin)\n",
        "        left = int(i[1] - i[2] - margin)\n",
        "        \n",
        "        if top < 0:\n",
        "            top = 0\n",
        "        if left < 0:\n",
        "            left = 0\n",
        "\n",
        "        start_point = (top, left)\n",
        "        end_point = (int(top+2*(i[2] + margin)), int(left+2*(i[2] + margin)))\n",
        "\n",
        "        cell = img[start_point[1]:end_point[1], start_point[0]:end_point[0]]\n",
        "\n",
        "        features = characterize(cell)\n",
        "        label = model.predict([features])\n",
        "        thickness = 2\n",
        "\n",
        "        if label == 'Dead':\n",
        "            cimg = cv2.rectangle(cimg, start_point, end_point, (0,0,255), thickness)\n",
        "            # cv2.circle(cimg,(i[0],i[1]),int(i[2] + margin),(0,0,255),1)\n",
        "            dead_count+=1\n",
        "        else:\n",
        "            cimg = cv2.rectangle(cimg, start_point, end_point, (0,255,0), thickness)\n",
        "            # cv2.circle(cimg,(i[0],i[1]),int(i[2] + margin),(0,255,0),1)\n",
        "            alive_count+=1\n",
        "\n",
        "    return dead_count, alive_count, cimg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C67lAKamaSMg"
      },
      "source": [
        "### Detect cells and classify them"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhyYcwvUU7RK"
      },
      "source": [
        "def detect_and_classify(img):\n",
        "    \n",
        "    img_lab = change_color_space(img)\n",
        "    channels = select_important_channels(img_lab)\n",
        "    cells = detect_cells(channels)\n",
        "    knn = load_model(\"/drive/Shareddrives/PDI/Dataset/knnpickle_file_colors.pickle\")\n",
        "    \n",
        "    dead_count, alive_count, out_img = classify_cells(img, cells, knn)\n",
        "\n",
        "    total_cells = dead_count + alive_count\n",
        "\n",
        "    if DEBUG:\n",
        "        plt.figure(figsize=(50,50))\n",
        "        plt.xticks([])\n",
        "        plt.yticks([])\n",
        "        plt.grid(False)\n",
        "\n",
        "        plt.imshow(cv2.cvtColor(out_img, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "    print(f'\\\n",
        "    Número total de células: {total_cells}\\n\\\n",
        "    Número total de células mortas: {dead_count} ({100*dead_count/total_cells:.2f}%)\\n\\\n",
        "    Número total de células vivas: {alive_count} ({100*alive_count/total_cells:.2f}%)')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBZhYAldaas9"
      },
      "source": [
        "# Usage example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C13CpWu90_v2"
      },
      "source": [
        "## Read image\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gbrbQfyGfP8I"
      },
      "source": [
        "img = cv2.imread(\"/drive/Shareddrives/PDI/Results/dataset1.jpg\")\n",
        "\n",
        "if DEBUG :\n",
        "    show_cvt(img, 15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tYRieS5-bM6V"
      },
      "source": [
        "## Detect, classify and count cells in image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TPW-p01GXo1Y",
        "outputId": "2d15e49c-86b3-4d76-fa25-f960b6346182"
      },
      "source": [
        "detect_and_classify(img)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "    Número total de células: 971\n",
            "    Número total de células mortas: 844 (86.92%)\n",
            "    Número total de células vivas: 127 (13.08%)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}