{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dataset_creator.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vernalhav/image_processing_project/blob/main/dataset_creator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NfS1L3rThtAh",
        "outputId": "2eaee0eb-6622-43c6-a019-dd6e45f63b50"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3vxSZ-3fP8H"
      },
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import imutils\n",
        "import mahotas as mt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czeMq-WBV5R6"
      },
      "source": [
        "def extract_color_histogram(image, bins=(2, 2, 2)):\n",
        "\t# extract a 3D color histogram from the HSV color space using\n",
        "\t# the supplied number of `bins` per channel\n",
        "\thsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
        "\thist = cv2.calcHist([hsv], [0, 1, 2], None, bins,\n",
        "\t\t[0, 180, 0, 256, 0, 256])\n",
        " \n",
        "\t# handle normalizing the histogram if we are using OpenCV 2.4.X\n",
        "\tif imutils.is_cv2():\n",
        "\t\thist = cv2.normalize(hist)\n",
        "\t# otherwise, perform \"in place\" normalization in OpenCV 3 (I\n",
        "\t# personally hate the way this is done\n",
        "\telse:\n",
        "\t\tcv2.normalize(hist, hist)\n",
        "  \n",
        "\t# return the flattened histogram as the feature vector\n",
        "\treturn hist.flatten()\n",
        "\n",
        "def extract_sobel(image):\n",
        "    NUM_FILTERS = 16\n",
        "    gabor = []\n",
        "    \n",
        "    for i in range(NUM_FILTERS):\n",
        "        gabor.append(cv2.getGaborKernel((5, 5), 8.0, (np.pi/NUM_FILTERS) * (i), 5.0, 0.5, 0, ktype=cv2.CV_32F))\n",
        "\n",
        "    filtered = []\n",
        "    \n",
        "    for i in range(NUM_FILTERS):\n",
        "        filtered_img = cv2.filter2D(image,3,gabor[i])\n",
        "        filtered_img = ((filtered_img/np.max(filtered_img))*255).astype(np.uint8)\n",
        "        filtered_img = cv2.cvtColor(filtered_img, cv2.COLOR_BGR2GRAY)\n",
        "        filtered_img = cv2.bitwise_not(filtered_img)\n",
        "        filtered.append(cv2.resize(filtered_img, (10,10)))\n",
        "\n",
        "    return np.array(filtered)\n",
        "\n",
        "def extract_haralick(image):\n",
        "        # calculate haralick texture features for 4 types of adjacency\n",
        "        textures = mt.features.haralick(image)\n",
        "\n",
        "        # take the mean of it and return it\n",
        "        ht_mean = textures.mean(axis=0)\n",
        "        return ht_mean\n",
        "\n",
        "def characterize(img):\n",
        "    img = cv2.resize(img,(30,30))\n",
        "    \n",
        "    #extract color and shape features\n",
        "    colors = extract_color_histogram(img)\n",
        "    \n",
        "    # shapes = extract_haralick(img)    \n",
        "    shapes = extract_sobel(img)\n",
        "\n",
        "    features = []\n",
        "    features = np.concatenate((features, colors.flatten()), axis=None)\n",
        "\n",
        "    for shape in shapes:\n",
        "        features = np.concatenate((features, shape.flatten()), axis=None)\n",
        "    \n",
        "    return features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39Uaja87UBnX"
      },
      "source": [
        "## Reading images and extracting features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4JZAKrFajcs"
      },
      "source": [
        "IMGS_PATH = \"/drive/Shareddrives/PDI/Dataset/Segmented\"\n",
        "\n",
        "classes = ['Dead', \"Alive\"]\n",
        "\n",
        "## creating dataset\n",
        "dataset = []\n",
        "labels = []\n",
        "for label in classes:\n",
        "    img_folder = os.path.join(IMGS_PATH, label)\n",
        "    for img_name in os.listdir(img_folder):\n",
        "        img_path = os.path.join(img_folder, img_name)\n",
        "        img = cv2.imread(img_path)\n",
        "        features = characterize(img)\n",
        "        dataset.append(features)\n",
        "        labels.append(label)\n",
        "\n",
        "dataset = np.array(dataset)\n",
        "labels = np.array(labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RyaQhqTtSpRX"
      },
      "source": [
        "## Preparing training dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WG7522sCSoun"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "import seaborn as sns\n",
        "sns.set()\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(dataset, labels, random_state=2,test_size=0.4, stratify=labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMkZRL2jFOjh"
      },
      "source": [
        "## KNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8yNUzvlKj5gh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69d20075-6b0f-4c40-e813-928dc1b1dffa"
      },
      "source": [
        "knn = KNeighborsClassifier(n_neighbors=3, metric='euclidean')\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "y_pred_knn = knn.predict(X_test)\n",
        "# print(y_pred_knn, y_test)\n",
        "\n",
        "print(\"Confustion Matrix: \", confusion_matrix(y_test, y_pred_knn))\n",
        "print(\"Accuracy: \", accuracy_score(y_test, y_pred_knn))\n",
        "print(\"Precision for each class: \", precision_score(y_test, y_pred_knn, average=None))\n",
        "print(\"Recall for each class: \", recall_score(y_test, y_pred_knn, average=None))\n",
        "print(\"F1 score for each class: \", f1_score(y_test, y_pred_knn, average=None))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confustion Matrix:  [[ 5  2]\n",
            " [ 0 34]]\n",
            "Accuracy:  0.9512195121951219\n",
            "Precision for each class:  [1.         0.94444444]\n",
            "Recall for each class:  [0.71428571 1.        ]\n",
            "F1 score for each class:  [0.83333333 0.97142857]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J8o7W9dtFTpw"
      },
      "source": [
        "## SVC\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SlS7_3hXFaVB",
        "outputId": "f1fd27ca-61d9-4116-da07-fdfb2a5ed1e1"
      },
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "clf_svm = LinearSVC(random_state=9)\n",
        "\n",
        "clf_svm.fit(X_train, y_train)\n",
        "\n",
        "y_pred_svc = clf_svm.predict(X_test)\n",
        "\n",
        "print(\"Accuracy: \", accuracy_score(y_test, y_pred_svc))\n",
        "print(\"Precision for each class: \", precision_score(y_test, y_pred_svc, average=None))\n",
        "print(\"Recall for each class: \", recall_score(y_test, y_pred_svc, average=None))\n",
        "print(\"F1 score for each class: \", f1_score(y_test, y_pred_svc, average=None))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy:  0.9512195121951219\n",
            "Precision for each class:  [1.         0.94444444]\n",
            "Recall for each class:  [0.71428571 1.        ]\n",
            "F1 score for each class:  [0.83333333 0.97142857]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-XsDbZOeTEyd"
      },
      "source": [
        "## Saving the best model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qECR57Nr2xm"
      },
      "source": [
        "#saving the model into a file\n",
        "import pickle\n",
        "MODEL_PATH = \"/drive/Shareddrives/PDI/Dataset\"\n",
        "knnPickle = open(os.path.join(MODEL_PATH, 'knn_strat_sobel_.pickle'), 'wb') \n",
        "pickle.dump(knn, knnPickle) \n",
        "knnPickle.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lz2Ya69BSkr6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}